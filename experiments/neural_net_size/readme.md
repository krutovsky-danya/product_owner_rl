# Гипотеза:
Увеличение размера нейронной сети приведёт к улучшению эффективности агента в игре.

# Метрики оценки:
* Процент побед — доля успешных исходов среди всех проведённых игр.
* Минимальный победный спринт — наименьшее количество шагов или действий, необходимых агенту для достижения победы.
* Распределение победных спринтов — анализ изменений в распределении количества шагов или действий, требуемых для победы, с целью определения, произошло ли смещение в сторону более эффективных стратегий.

# Метод достижения результата:
1. Увеличить размер нейронной сети в несколько раз, сохраняя общую архитектуру и параметры обучения.
2. Провести серию из пяти обучающих экспериментов, каждый на наборе данных, состоящем из 1500 траекторий игры.
3. Переиспользовать данные, полученные из предыдущего эксперимента с размером сети 512 нейронов для выходов внутренних слоёв.

# Результат:
Гипотеза не получила подтверждения. 
Увеличение размера нейронной сети не привело к улучшению эффективности агента. 
Напротив, агенты с меньшим размером внутреннего представления (256 нейронов) показали более высокие результаты по проценту побед по сравнению с агентами, имеющими большее внутреннее представление.

Статистическая значимость результатов подтверждается значением p-value, равным 1.4990e-06, что указывает на высокую вероятность того, что наблюдаемые различия не являются случайными.

Примечательно, что время, необходимое агентам для достижения победы (победные спринты), статистически не различается между агентами с разным размером внутреннего представления.

Аналогичные результаты были получены для агентов, обученных на GPU, хотя статистическая значимость различий была ниже (p-value = 0.0077).

При дальнейшем увеличении размера внутреннего представления не наблюдалось качественного изменения в показателях эффективности агентов.

Различия в результатах также могут быть обусловлены разным аппаратным обеспечением (CPU и GPU). 
В частности, было замечено ухудшение доли побед агента, обученного на GPU, по сравнению с агентом, обученным на CPU. 
Это может быть связано с различиями в точности вычислений: на CPU используется двойная точность чисел с плавающей точкой, а на GPU — одинарная.
